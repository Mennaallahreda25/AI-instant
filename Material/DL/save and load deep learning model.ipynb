{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d90a7cb",
   "metadata": {},
   "source": [
    "# How to Save and Load Your Keras Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d48c7c",
   "metadata": {},
   "source": [
    "# Save Your Neural Network Model to JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58462e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9becc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import os\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    " \n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c6700",
   "metadata": {},
   "source": [
    "# Save Your Neural Network Model to YAML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6b9bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo pip install PyYAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d5f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MLP for Pima Indians Dataset serialize to YAML and HDF5\n",
    "from tensorflow.keras.models import Sequential, model_from_yaml\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import os\n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    " \n",
    "# load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1cff92",
   "metadata": {},
   "source": [
    "# Save Model Weights and Architecture Together\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f2545",
   "metadata": {},
   "source": [
    "How to Save a Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d581dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset saved to single file\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load pima indians dataset\n",
    "dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# save model and architecture to single file\n",
    "model.save(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b907708",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# equivalent to: model.save(\"model.h5\")\n",
    "from tensorflow.keras.models import save_model\n",
    "save_model(model, \"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f30169a",
   "metadata": {},
   "source": [
    "How to Load a Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe60adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load and evaluate a saved model\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('model.h5')\n",
    "# summarize model.\n",
    "model.summary()\n",
    "# load dataset\n",
    "dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# evaluate the model\n",
    "score = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6e4a6a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-11T00:16:36.802389Z",
     "start_time": "2023-03-11T00:16:36.780447Z"
    }
   },
   "outputs": [],
   "source": [
    "###########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e52551",
   "metadata": {},
   "source": [
    "# summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a67a51",
   "metadata": {},
   "source": [
    "Training a neural network/deep learning model usually takes a lot of time, particularly if the hardware capacity of the system doesnâ€™t match up to the requirement. Once the training is done, we save the model to a file. To reuse the model at a later point of time to make predictions, we load the saved model.\n",
    "Through Keras, models can be saved in three formats:\n",
    "\n",
    "YAML format/\n",
    "JSON format/\n",
    "HDF5 format\n",
    "\n",
    "YAML and JSON files store only model structure, whereas, HDF5 file stores complete neural network model along with structure and weights. Therefore, if the model structure is saved using YAML or JSON format, weights should be stored in an HDF5 file to store the entire model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02f191",
   "metadata": {},
   "source": [
    "# Loading the dataset and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e660c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import boston_housing\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets)= boston_housing.load_data()\n",
    "\n",
    "mean = train_data.mean(axis = 0)\n",
    "train_data-= mean\n",
    "std = train_data.std(axis = 0)\n",
    "\n",
    "train_data/= std\n",
    "test_data-= mean\n",
    "test_data/= std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467317a7",
   "metadata": {},
   "source": [
    "# Training a neural network model on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf9ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation =\"relu\", input_shape =(train_data.shape[1], )))\n",
    "model.add(layers.Dense(64, activation =\"relu\"))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(optimizer =\"rmsprop\", loss =\"mse\", metrics =[\"mae\"])\n",
    "loss, accuracy = model.evaluate(test_data, test_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af470d6",
   "metadata": {},
   "source": [
    "# Saving and reloading model in HDF5 file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f09878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving and reloading model in HDF5 file format\n",
    "from keras.models import load_model\n",
    "model.save(\"network.h5\")\n",
    "loaded_model = load_model(\"network.h5\")\n",
    "loss, accuracy = loaded_model.evaluate(test_data, test_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de48d6",
   "metadata": {},
   "source": [
    "# Saving and reloading model in JSON file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66000a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model structure to a JSON file\n",
    "\n",
    "model_json = model.to_json() # with open(\"network.json\", \"w\") as json_file:\n",
    "\tjson_file.write(model_json)\n",
    "\n",
    "# Saving weights of the model to a HDF5 file\n",
    "model.save_weights(\"network.h5\")\n",
    "\n",
    "# Loading JSON file\n",
    "json_file = open(\"network.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Loading weights\n",
    "loaded_model.load_weights(\"network.h5\")\n",
    "loss, accuracy = loaded_model.evaluate(test_data, test_targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8fe99c",
   "metadata": {},
   "source": [
    "# Saving and reloading model in YAML file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16abf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving model structure to a YAML file\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"network.yaml\", \"w\") as yaml_file:\n",
    "\tyaml_file.write(model_yaml)\n",
    "\n",
    "# Saving weights of the model to a HDF5 file\n",
    "model.save_weights(\"network.h5\")\n",
    "\n",
    "# Loading YAML file\n",
    "yaml_file = open(\"network.yaml\", 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "\n",
    "# Loading weights\n",
    "loaded_model.load_weights(\"network.h5\")\n",
    "loss, accuracy = loaded_model.evaluate(test_data, test_targets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

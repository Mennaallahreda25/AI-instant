{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d93c52fa",
   "metadata": {},
   "source": [
    "# Important Parameters of light GBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be701fb",
   "metadata": {},
   "source": [
    "• task: default value = train ; options = train, prediction; Specifies the task we wish to perform which is either train or prediction.     \n",
    "• application: default=regression, type=enum, options=         \n",
    "options:     \n",
    "1. regression: perform regression task    \n",
    "2. binary : Binary classification       \n",
    "3. multiclass: Multiclass Classification      \n",
    "4. lambdarank: lambdarank application      \n",
    "• data: type=string; training data, LightGBM will train from this data           \n",
    "• num iterations: number of boosting iterations to be performed ; default=100; type=int             \n",
    "• num_leaves : number of leaves in one tree ; default = 31 ;type =int             \n",
    "• device : default= cpu; options = gpu,cpu. Device on which we want to train our model. Choose GPU for faster training.      \n",
    "• max_depth: Specify the max depth to which tree will grow. This parameter is used to deal with overfitting.            \n",
    "• min_data_in_leaf: Min number of data in one leaf.                  \n",
    "• feature_fraction: default=1; specifies the fraction of features to be taken for each iteration         \n",
    "• bagging fraction: default=1; specifies the fraction of data to be used for each iteration and is generally used to speed up the training and avoid overfitting.                \n",
    "• min_gain_to_ split: default=. 1; min gain to perform splitting                \n",
    "• max_bin: max number of bins to bucket the feature values.                 \n",
    "• min_data_in_bin: min number of data in one bin                \n",
    "• num_threads: default=OpenMP_default, type=int; Number of threads for Light GBM.                    \n",
    "• label: type=string; specify the label column                \n",
    "• categorical_feature: type=string; specify the categorical features we want to use for training our model               \n",
    "• num_class: default=1; type=int; used only for multi-class classification  \n",
    "\n",
    "# Tuning for overfitting\n",
    "\n",
    "The following parameters can be used to control overfitting:             \n",
    "• max_bin: the maximum numbers bins that feature values are bucketed in. A smaller max_bin reduces overfitting.        \n",
    "• min_child_weight: the minimum sum hessian for a leaf. In conjuction with min_child_samples, larger values reduce overfitting.    \n",
    "• bagging_fraction and bagging_freq: enables bagging (subsampling) of the training data. Both values need to be set for bagging to be used. The frequency controls how often (iteration) bagging is used. Smaller fractions and frequencies reduce overfitting.    \n",
    "• feature_fraction: controls the subsampling of features used for training (as opposed to subsampling the actual training data in the case of bagging). Smaller fractions reduce overfitting.     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b06052",
   "metadata": {},
   "source": [
    "# LightGBM Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "import lightgbm as ltb\n",
    "dataset = datasets.load_breast_cancer () # Load and return the breast cancer wisconsin dataset (classification).\n",
    "X = dataset. data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "model = Itb.LGBMClassifier()\n",
    "model.fit (X_train, y_train) \n",
    "print (\"model :\",model)\n",
    "expected_y = y_test\n",
    "predicted_y = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(\"metrics classification_report: \",metrics.classification_report(expected_y, predicted_y))\n",
    "print(\"metrics confusion_matrix :\",metrics.confusion_matrix(expected_y, predicted_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a21842",
   "metadata": {},
   "source": [
    "# LightGBM Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d293f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets \n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns pit.style.use('ggplot')\n",
    "import lightgbm as ltb\n",
    "dataset = datasets. load boston () # Load and return the boston house-prices dataset (regression).\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "model = Itb. LGBMRegressor ()\n",
    "model.fit(X_train, y_train) \n",
    "print (\"model:\", model)\n",
    "expected_y = y_test\n",
    "predicted_y = model.predict(X_test)\n",
    "print(\"metrics r2_score:\", metrics.r2_score(expected_y, predicted _y))\n",
    "print(\"metrics mean_squared :\", metrics.mean_squared_log_error (expected_y, predicted_y))\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.regplot (expected_y, predicted_y, fit_reg=True, scatter_kws={\"s\": 100}) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c389b4",
   "metadata": {},
   "source": [
    "# Setting the Model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb \n",
    "from sklearn import metrics \n",
    "from sklearn import datasets \n",
    "from sklearn.model_selection import train_test_split\n",
    "dataset = datasets.load boston\n",
    "X = dataset. data\n",
    "y = dataset.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "lgb_train = lgb.Dataset (X_train, y_train)\n",
    "lgb_eval = lgb.Dataset (X_test, y_test, reference=lgb_train)\n",
    "params = {'boosting_type': 'gbdt','objective': 'regression','num_leaves': 28,'learning_rate': 0.05,'feature_fraction': 0.9,\n",
    "          'bagging_fraction': 0.8,'bagging_freq': 5,'verbose': 1}\n",
    "gbm = lgb.train(params, lgb_train,num_boost_round=20,valid_sets=lgb_eval,early_stopping_rounds=5)\n",
    "gbm.save_model ('model.txt')\n",
    "y_pred = gbm.predict (X_test, num_iteration=gbm.best_iteration)\n",
    "print(\"metrics r2_score:\", metrics.r2_score (y_test, y_pred))\n",
    "print(\"metrics mean_squared error:\", metrics.mean_squared_log_error (y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e762c2",
   "metadata": {},
   "source": [
    "output:\n",
    "    \n",
    "metrics r2_score: 0.6707990924263482                  \n",
    "metrics mean squared error: 0.04073686960222717"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0966e6",
   "metadata": {},
   "source": [
    "# References: \n",
    "\n",
    "HttpS://www.analyticsvidhya.com/blog/2017/06/which-algorithm-takes-the-crown-light-gbm-vs-xgboost/\n",
    "\n",
    "https://www.avanwyk.com/an-overview-of-lightgbm/\n",
    "\n",
    "https://www.dezyre.com/recipes/use-lightgbm-classifier-and-regressor-in-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4a3e81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
